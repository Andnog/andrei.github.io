<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Andrei Noguera</title>
    <link>http://localhost:1313/project/</link>
      <atom:link href="http://localhost:1313/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Sun, 27 Oct 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/media/icon_hu14089566703181701121.png</url>
      <title>Projects</title>
      <link>http://localhost:1313/project/</link>
    </image>
    
    <item>
      <title>Github</title>
      <link>http://localhost:1313/project/github/</link>
      <pubDate>Sun, 27 Oct 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/github/</guid>
      <description>&lt;p&gt;Showcases a diverse range of tutorials, personal projects, and technical resources aimed at demonstrating my skills.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Speech Generator with Transformers</title>
      <link>http://localhost:1313/project/speech-generator/</link>
      <pubDate>Wed, 01 Dec 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/speech-generator/</guid>
      <description>&lt;h2 id=&#34;project-overview&#34;&gt;Project Overview&lt;/h2&gt;
&lt;p&gt;This project, developed as part of the &amp;ldquo;Principles of Deep Learning&amp;rdquo; course in the Master&amp;rsquo;s in Data Science program, focused on building a speech generator using deep learning techniques, specifically transformers. The model was fine-tuned with presidential speeches and related materials to produce coherent text outputs.&lt;/p&gt;
&lt;h3 id=&#34;goals&#34;&gt;Goals&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Validate knowledge acquired in the course by applying deep learning techniques to solve a real-world problem.&lt;/li&gt;
&lt;li&gt;Use publicly available material to generate new text information.&lt;/li&gt;
&lt;li&gt;Train a deep learning model to generate speeches based on input text.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;main-objective&#34;&gt;Main Objective&lt;/h3&gt;
&lt;p&gt;To develop a deep learning model capable of generating speeches, trained on datasets including speeches from former Mexican presidents Felipe Calderón and Enrique Peña Nieto, and official press releases from presidential events.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;theoretical-framework&#34;&gt;Theoretical Framework&lt;/h2&gt;
&lt;h3 id=&#34;deep-learning&#34;&gt;Deep Learning&lt;/h3&gt;
&lt;p&gt;Deep learning is a subset of machine learning that utilizes neural networks with multiple layers to simulate human brain behavior. These networks are designed to process and analyze large datasets, enabling predictions and classifications.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;DL&#34; srcset=&#34;
               /project/speech-generator/resources/deeplearning_chart_hu2373431881331503144.webp 400w,
               /project/speech-generator/resources/deeplearning_chart_hu17305596546662484445.webp 760w,
               /project/speech-generator/resources/deeplearning_chart_hu14300440690594667113.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/speech-generator/resources/deeplearning_chart_hu2373431881331503144.webp&#34;
               width=&#34;426&#34;
               height=&#34;412&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;transformers&#34;&gt;Transformers&lt;/h3&gt;
&lt;p&gt;Transformers are neural network architectures that excel in sequence-to-sequence tasks, such as language translation, text generation, and speech-to-text transformation. Unlike recurrent neural networks (RNNs), transformers leverage self-attention mechanisms to identify contextual relationships between words, allowing for faster and more parallelizable computations.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Transformers&#34; srcset=&#34;
               /project/speech-generator/resources/transformers_hu16626568564970676515.webp 400w,
               /project/speech-generator/resources/transformers_hu15729801764741662005.webp 760w,
               /project/speech-generator/resources/transformers_hu8283865407848857783.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/speech-generator/resources/transformers_hu16626568564970676515.webp&#34;
               width=&#34;624&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;business-case&#34;&gt;Business Case&lt;/h2&gt;
&lt;p&gt;Natural Language Processing (NLP) is integral to Artificial Intelligence (AI), enabling machines to work with unstructured text data. Text generation, a challenging NLP application, has widespread utility in customer service (chatbots) and journalism (automated reporting). This project aimed to leverage transformers to create a tool capable of generating coherent speeches in Spanish, tailored to the dataset&amp;rsquo;s context.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;data-collection&#34;&gt;Data Collection&lt;/h2&gt;
&lt;p&gt;The dataset comprised 8,454 speech documents extracted from:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Official Mexican Government Sites&lt;/strong&gt;: Speeches and press releases from the presidency&amp;rsquo;s archives.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Wayback Machine&lt;/strong&gt;: Archived speeches from previous administrations.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The extraction process utilized Python libraries such as &lt;code&gt;BeautifulSoup&lt;/code&gt; and &lt;code&gt;requests&lt;/code&gt; to scrape and preprocess the data, which was stored as text files for model training.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;methodology&#34;&gt;Methodology&lt;/h2&gt;
&lt;p&gt;The project followed the CRISP-DM methodology, consisting of:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Business Understanding&lt;/strong&gt;: Researching existing text-generation methods and identifying use cases.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data Understanding&lt;/strong&gt;: Extracting and verifying speeches for training.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data Preparation&lt;/strong&gt;: Creating a corpus, tokenizing text, and building frequency dictionaries.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Modeling&lt;/strong&gt;: Evaluating deep learning frameworks (&lt;code&gt;PyTorch&lt;/code&gt;, &lt;code&gt;TensorFlow&lt;/code&gt;) and using pretrained transformer models.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Evaluation&lt;/strong&gt;: Measuring model performance using metrics like loss and manual inspection of generated text.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Methodology&#34; srcset=&#34;
               /project/speech-generator/resources/CRISP-DM_hu12083214195692133757.webp 400w,
               /project/speech-generator/resources/CRISP-DM_hu6600300787577855483.webp 760w,
               /project/speech-generator/resources/CRISP-DM_hu15258616431478168041.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/speech-generator/resources/CRISP-DM_hu12083214195692133757.webp&#34;
               width=&#34;555&#34;
               height=&#34;550&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;models-implemented&#34;&gt;Models Implemented&lt;/h2&gt;
&lt;h3 id=&#34;model-1-pytorch&#34;&gt;Model 1: PyTorch&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Framework&lt;/strong&gt;: PyTorch&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pretrained Model&lt;/strong&gt;: Roberta&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Result&lt;/strong&gt;: Low loss but incoherent text generation.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;model-2-tensorflow&#34;&gt;Model 2: TensorFlow&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Framework&lt;/strong&gt;: TensorFlow&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pretrained Model&lt;/strong&gt;: AutoModel&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Result&lt;/strong&gt;: Improved coherence but repetitive text.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;model-3-gpt-2-fine-tuned&#34;&gt;Model 3: GPT-2 Fine-tuned&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Framework&lt;/strong&gt;: TensorFlow&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Configuration&lt;/strong&gt;: Medium GPT-2 model, fine-tuned with 1,000 epochs.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Result&lt;/strong&gt;: Most coherent and contextually relevant text outputs, though some results deviated from the input topic.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;final-model-configuration&#34;&gt;Final Model Configuration&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Model 3: GPT-2 Fine-tuned&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;gpt2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;finetune&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sess&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;dataset&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;input.txt&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;model_name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;355M&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;steps&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;restore_from&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;fresh&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;run_name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;run1&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;print_every&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;50&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;sample_every&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;save_every&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;500&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;playground&#34;&gt;Playground&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Discursero Web Application&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;Discurselo&lt;/strong&gt; playground provides an interactive interface for generating speeches using artificial intelligence. Users can customize various parameters to create tailored and coherent texts based on their specific needs.&lt;/p&gt;
&lt;h3 id=&#34;features&#34;&gt;Features&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Input Field&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Users can enter a phrase or sentence to prompt the AI for speech generation.&lt;/li&gt;
&lt;li&gt;Example prompt: &lt;em&gt;&amp;ldquo;México necesita apoyo de&amp;hellip;&amp;rdquo;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Output Display&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The generated speech is displayed in the output box, showing the result based on the input and configuration.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Customizable Settings&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Number of Characters&lt;/strong&gt;: Adjust the length of the generated speech.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Temperature&lt;/strong&gt;: Set the creativity of the text generation. A lower temperature produces deterministic results, while a higher value increases randomness and variability.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Number of Speeches&lt;/strong&gt;: Generate multiple outputs for comparison and selection.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Action Button&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A single button (&lt;em&gt;&amp;ldquo;Generar Discurso&amp;rdquo;&lt;/em&gt;) triggers the generation process, making it simple and intuitive for users.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Playground&#34; srcset=&#34;
               /project/speech-generator/resources/Playgroud_hu14645128099872404743.webp 400w,
               /project/speech-generator/resources/Playgroud_hu10518211611982399857.webp 760w,
               /project/speech-generator/resources/Playgroud_hu6982698190391628828.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/speech-generator/resources/Playgroud_hu14645128099872404743.webp&#34;
               width=&#34;760&#34;
               height=&#34;395&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;sample-outputs&#34;&gt;Sample Outputs&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Prompt&lt;/strong&gt;: &amp;ldquo;El grave problema de inseguridad de México es&amp;rdquo;&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;

  &lt;span class=&#34;inline-block  pr-1&#34;&gt;
    &lt;svg style=&#34;height: 1em; transform: translateY(0.1em);&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;M7.5 8.25h9m-9 3H12m-9.75 1.51c0 1.6 1.123 2.994 2.707 3.227c1.129.166 2.27.293 3.423.379c.35.026.67.21.865.501L12 21l2.755-4.132a1.14 1.14 0 0 1 .865-.502a48.172 48.172 0 0 0 3.423-.379c1.584-.233 2.707-1.626 2.707-3.228V6.741c0-1.602-1.123-2.995-2.707-3.228A48.394 48.394 0 0 0 12 3c-2.392 0-4.744.175-7.043.513C3.373 3.746 2.25 5.14 2.25 6.741z&#34;/&gt;&lt;/svg&gt;
  &lt;/span&gt; Generated Text: &lt;hr class=&#34;m-0-imp&#34;&gt; 
&#34;El grave problema de inseguridad de México es claramente construir un México de leyes y de instituciones de seguridad.&lt;br&gt;&lt;br&gt;
Por supuesto, quisiera señalar que en la materia, no sólo eso, sino que a nivel nacional, por cierto, desde la especie de la democracia y de la voluntad política, de la libertad, de la democracia y de instituciones democráticas, puede ser una de las mejores, una de las medidas que hoy realizan, una de las mejores plataformas para que sea la mayor responsabilidad de la sociedad.&lt;br&gt;&lt;br&gt;
Asimismo, así como el hecho de que se han venido impulsando una mayor desarrollo en las instituciones de seguridad pública y de justicia, eso es lo que enfrentamos.&lt;br&gt;&lt;br&gt;
Muchas gracias.
&#34;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;strong&gt;Prompt&lt;/strong&gt;: &amp;ldquo;El compromiso del Estado Mexicano con las mujeres del país&amp;rdquo;&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;

  &lt;span class=&#34;inline-block  pr-1&#34;&gt;
    &lt;svg style=&#34;height: 1em; transform: translateY(0.1em);&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;M7.5 8.25h9m-9 3H12m-9.75 1.51c0 1.6 1.123 2.994 2.707 3.227c1.129.166 2.27.293 3.423.379c.35.026.67.21.865.501L12 21l2.755-4.132a1.14 1.14 0 0 1 .865-.502a48.172 48.172 0 0 0 3.423-.379c1.584-.233 2.707-1.626 2.707-3.228V6.741c0-1.602-1.123-2.995-2.707-3.228A48.394 48.394 0 0 0 12 3c-2.392 0-4.744.175-7.043.513C3.373 3.746 2.25 5.14 2.25 6.741z&#34;/&gt;&lt;/svg&gt;
  &lt;/span&gt; Generated Text: &lt;hr class=&#34;m-0-imp&#34;&gt; 
&#34;El compromiso del Estado Mexicano con las mujeres del país, es posible dar un gran camino para abrir a la gente la oportunidad de bienestar y el progreso de todas en el país.&lt;br&gt;&lt;br&gt;
Segundo. El México que se encuentra con la búsqueda de las niñas, los niños y los jóvenes, es un México de desarrollo social y de bienestar para todos.&lt;br&gt;&lt;br&gt;
Tercero. El México que encabeza por el que presenciamos el mes de julio de 2017, aprovechamos el esfuerzo de todos los niveles de Gobierno para contribuir a la construcción de una gente abierta.&lt;br&gt;&lt;br&gt;
Cuarto. El México que encabeza por el que encabeza el Presidente Enrique Peña Nieto, a través de los precios de generar los apoyos a los nuevos derechos fundamentales de los derechos humanos.&lt;br&gt;&lt;br&gt;
Hoy, se encuentra con la búsqueda de la gente, pues llegamos a los nuevos derechos fundamentales, y sigue siendo mejor.&#34;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The project demonstrated the potential of deep learning for text generation tasks. Key findings include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pretrained models save significant time and resources for training.&lt;/li&gt;
&lt;li&gt;Model coherence can be improved by narrowing training datasets to specific topics.&lt;/li&gt;
&lt;li&gt;Fine-tuning large-scale models like GPT-2 produces the best results but requires significant computational power.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;future-work&#34;&gt;Future Work&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Increase training epochs for better performance.&lt;/li&gt;
&lt;li&gt;Create topic-specific models to improve contextual relevance.&lt;/li&gt;
&lt;li&gt;Experiment with multilingual datasets for broader applicability.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;colaborations&#34;&gt;Colaborations&lt;/h3&gt;
&lt;p&gt;This project is a colaboration with Miguel Ángel Bernal&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Automated News Analysis with GCP</title>
      <link>http://localhost:1313/project/news/</link>
      <pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/news/</guid>
      <description>&lt;h2 id=&#34;project-overview&#34;&gt;Project Overview&lt;/h2&gt;
&lt;p&gt;This project, developed as a part of the &amp;ldquo;Cloud Computing&amp;rdquo; course in the Master&amp;rsquo;s in Data Science program, demonstrates an automated news analysis system using various Google Cloud Platform (GCP) services. The objective was to create a scalable, serverless solution for extracting, processing, and analyzing news articles from popular media outlets.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;summary&#34; srcset=&#34;
               /project/news/resources/SUMMARY_hu9664879717778521629.webp 400w,
               /project/news/resources/SUMMARY_hu10466667494443147224.webp 760w,
               /project/news/resources/SUMMARY_hu10514249569512975497.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/news/resources/SUMMARY_hu9664879717778521629.webp&#34;
               width=&#34;760&#34;
               height=&#34;282&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;goals&#34;&gt;Goals&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Implement a cloud-based solution for a real-world problem.&lt;/li&gt;
&lt;li&gt;Develop a data science project deployable on the cloud.&lt;/li&gt;
&lt;li&gt;Utilize Google Cloud Platform tools to streamline the process.&lt;/li&gt;
&lt;li&gt;Propose an innovative solution that could benefit companies needing media monitoring.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;business-use-case&#34;&gt;Business Use Case&lt;/h3&gt;
&lt;p&gt;Many organizations rely on press monitoring services to track relevant news about their sector, evaluate brand presence, and adjust communication strategies. Despite the availability of electronic solutions, many still depend on manual methods, leading to time and resource inefficiencies.&lt;/p&gt;
&lt;h3 id=&#34;solution-requirements&#34;&gt;Solution Requirements&lt;/h3&gt;
&lt;p&gt;The solution needed to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Extract HTML and XML files from news sites.&lt;/li&gt;
&lt;li&gt;Automate processes using Google Cloud Platform.&lt;/li&gt;
&lt;li&gt;Perform text extraction, cleaning, and storage in a structured database.&lt;/li&gt;
&lt;li&gt;Implement Natural Language Processing (NLP) techniques to identify and analyze key entities.&lt;/li&gt;
&lt;li&gt;Visualize the insights on a user-friendly dashboard.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;gcp-tools-utilized&#34;&gt;GCP Tools Utilized&lt;/h2&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;tech used&#34; srcset=&#34;
               /project/news/resources/techs_used_hu11200484862602000508.webp 400w,
               /project/news/resources/techs_used_hu6825935607339017889.webp 760w,
               /project/news/resources/techs_used_hu13988790560792156940.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/news/resources/techs_used_hu11200484862602000508.webp&#34;
               width=&#34;760&#34;
               height=&#34;341&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Cloud Scheduler&lt;/strong&gt;: Schedules tasks to initiate news extraction twice daily.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cloud Functions&lt;/strong&gt;: Runs serverless code to extract headlines, publish dates, links, and full text.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cloud Pub/Sub&lt;/strong&gt;: Manages messaging between services, ensuring that extracted data flows smoothly through each stage.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cloud Storage&lt;/strong&gt;: Stores the raw HTML content for historical and backup purposes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;BigQuery&lt;/strong&gt;: Acts as the structured data warehouse for processed news data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data Studio&lt;/strong&gt;: Creates an interactive dashboard for visualizing analysis results.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Google Kubernetes Engine (GKE)&lt;/strong&gt;: Runs NLP models for entity recognition and text analysis.
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Docker&lt;/strong&gt;:  Used to containerize the application, ensuring consistency and portability.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cloud Run&lt;/strong&gt;: Deploys serverless containers for additional NLP tasks.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cloud Logging&lt;/strong&gt;: Monitors service performance and logs events for troubleshooting.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;data-science-workflow&#34;&gt;Data Science Workflow&lt;/h2&gt;
&lt;p&gt;The data science model focuses on processing raw news text to identify essential information. Key techniques include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Tokenization and Normalization&lt;/strong&gt;: Prepares text for analysis.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Frequency Analysis&lt;/strong&gt;: Highlights recurring terms.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;N-grams Analysis&lt;/strong&gt;: Uses unigrams, bigrams, trigrams, and quadrigrams for text insights with NLTK.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Named Entity Recognition (NER)&lt;/strong&gt;: Identifies named entities such as people, places, and organizations using spaCy.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The results of these analyses are stored in BigQuery for structured, queryable storage, and later visualized in Data Studio.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;data-schema&#34;&gt;Data Schema&lt;/h2&gt;
&lt;h3 id=&#34;key-tables&#34;&gt;Key Tables&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Notes Table&lt;/strong&gt;: Stores metadata and processed content for each news article.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Frequency Table&lt;/strong&gt;: Tracks the frequency of each word in the processed content.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;N-grams Table&lt;/strong&gt;: Stores n-gram counts for further analysis.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NER Table&lt;/strong&gt;: Contains recognized entities (e.g., persons, places, organizations) with occurrence counts.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;tech used&#34; srcset=&#34;
               /project/news/resources/DatabaseTables_hu6851130293813862887.webp 400w,
               /project/news/resources/DatabaseTables_hu4806471106134352514.webp 760w,
               /project/news/resources/DatabaseTables_hu6677739929682999115.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/news/resources/DatabaseTables_hu6851130293813862887.webp&#34;
               width=&#34;621&#34;
               height=&#34;301&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;architecture-and-workflow&#34;&gt;Architecture and Workflow&lt;/h2&gt;
&lt;p&gt;The system architecture is designed to be fully decoupled, serverless, and scalable. The core workflows are:&lt;/p&gt;
&lt;h3 id=&#34;workflow-1-news-extraction&#34;&gt;Workflow 1: News Extraction&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Cloud Scheduler triggers news extraction at specific intervals.&lt;/li&gt;
&lt;li&gt;Cloud Functions extract key details (title, date, link) from each news source.&lt;/li&gt;
&lt;li&gt;Extracted data is preprocessed and stored in Cloud Storage and BigQuery.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;workflow-2-news-analysis&#34;&gt;Workflow 2: News Analysis&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Cloud Scheduler triggers NLP analysis at scheduled times.&lt;/li&gt;
&lt;li&gt;The NLP model processes each article, performing frequency analysis and entity recognition.&lt;/li&gt;
&lt;li&gt;The results are stored in BigQuery and visualized in Data Studio.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;tech used&#34; srcset=&#34;
               /project/news/resources/ProjectFlow_hu10627101085534324064.webp 400w,
               /project/news/resources/ProjectFlow_hu7491263619185376250.webp 760w,
               /project/news/resources/ProjectFlow_hu17822350382704724148.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/news/resources/ProjectFlow_hu10627101085534324064.webp&#34;
               width=&#34;760&#34;
               height=&#34;174&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;architecture-diagram&#34;&gt;Architecture Diagram&lt;/h3&gt;
&lt;p&gt;The architecture includes Cloud Functions for individual tasks, Pub/Sub for message passing, BigQuery for data storage, and Data Studio for the dashboard, enabling easy monitoring and analysis.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;tech used&#34; srcset=&#34;
               /project/news/resources/achitecture_hu14717856938482271033.webp 400w,
               /project/news/resources/achitecture_hu4589275302579216269.webp 760w,
               /project/news/resources/achitecture_hu8169087343203014867.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/news/resources/achitecture_hu14717856938482271033.webp&#34;
               width=&#34;760&#34;
               height=&#34;432&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;dashboard&#34;&gt;Dashboard&lt;/h2&gt;
&lt;p&gt;A Data Studio dashboard was set up to present the analysis results. Key features include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Page 1&lt;/strong&gt;: Overview of collected news with filters by source, date, and keywords.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Page 2&lt;/strong&gt;: Word frequency and n-grams analysis.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Page 3&lt;/strong&gt;: Advanced n-grams and word cloud visualizations.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Page 4&lt;/strong&gt;: Named Entity Recognition (NER) analysis, including breakdowns by persons, places, and organizations.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pdf-example-report&#34;&gt;PDF Example Report&lt;/h3&gt;
&lt;p&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;This cloud-based solution for news analysis offers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt;: Efficiently automates tasks with minimal latency.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reliability&lt;/strong&gt;: Scheduled jobs ensure consistent performance.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cost-Effectiveness&lt;/strong&gt;: Serverless infrastructure reduces costs.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Usability&lt;/strong&gt;: Provides actionable insights through data-driven visualizations.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;future-improvements&#34;&gt;Future Improvements&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Integrating additional media sources for broader coverage.&lt;/li&gt;
&lt;li&gt;Expanding the NLP model to analyze more variables.&lt;/li&gt;
&lt;li&gt;Enhancing indexing and database relationships for richer analysis.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;colaborations&#34;&gt;Colaborations&lt;/h3&gt;
&lt;p&gt;This project is a colaboration with Miguel Ángel Bernal&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Sentiment Analysis on Twitter About COVID-19 Vaccination in Mexico</title>
      <link>http://localhost:1313/project/research/</link>
      <pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/research/</guid>
      <description>&lt;p&gt;Reasearch paper publication.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
